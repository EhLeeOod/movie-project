{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4041a3f1-cfa8-4aee-a753-befd3d9467cc",
   "metadata": {},
   "source": [
    "# Project 2 - Part 7 (Core)\n",
    "\n",
    "For this project you will create a streamlit app to get predictions from your best model.\n",
    "\n",
    "### Deliverables:\r\n",
    "- \r\n",
    "New notebook file for Preparing for streamli- t\r\n",
    "Models and data sav- ed\r\n",
    "app.py in main folder of repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51301c-112c-429d-859f-6d9d936108dd",
   "metadata": {},
   "source": [
    "# Part 1: Preparing Best Models for Streamlit\n",
    "\n",
    "- Define a filepaths dictionary and save it to config/filepaths.json  to include file paths for each component you will save (review below).\n",
    "\n",
    "- Copy your best models from part 6 into the new notebook. \n",
    "\n",
    "- Update your code to define the final public-facing class labels. \n",
    "\n",
    "## Saving Your Models\n",
    "\n",
    "### For your Machine Learning model:\n",
    "\n",
    "- Save your training data  ([X_train, y_train]​)\n",
    "\n",
    "- Save your test data ([X_test, y_test]​)​\n",
    "\n",
    "- Save your target_lookup dictionary and/or your label encoder\n",
    "\n",
    "- Save your best model\n",
    "\n",
    "### For your Deep NLP model:\n",
    "\n",
    "- Save your training data  (train_ds​)\n",
    "\n",
    "- Save your test data (test_ds​)​\n",
    "\n",
    "- Save your best neural network.\n",
    "\n",
    "Reminder: use safe_format='tf' to save the model in a folder of repo-friendly files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97d84a8-9416-4483-a178-da2e67d0fbda",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d67407-25d8-4e27-9e1b-1b14ddda7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db25724-2e33-461d-b31e-3f4ad7086c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "import tensorflow as tf\n",
    "# Increase column width\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "import tensorflow as tf\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "368097de-28ac-4a76-9c50-c10ee7cdeb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# ChatGPT function from LP\n",
    "import os\n",
    "def create_directories_from_paths(nested_dict):\n",
    "    \"\"\"OpenAI. (2023). ChatGPT [Large language model]. https://chat.openai.com \n",
    "    Recursively create directories for file paths in a nested dictionary.\n",
    "    Parameters:\n",
    "    nested_dict (dict): The nested dictionary containing file paths.\n",
    "    \"\"\"\n",
    "    for key, value in nested_dict.items():\n",
    "        if isinstance(value, dict):\n",
    "            # If the value is a dictionary, recurse into it\n",
    "            create_directories_from_paths(value)\n",
    "        elif isinstance(value, str):\n",
    "            # If the value is a string, treat it as a file path and get the directory path\n",
    "            directory_path = os.path.dirname(value)\n",
    "            # If the directory path is not empty and the directory does not exist, create it\n",
    "            if directory_path and not os.path.exists(directory_path):\n",
    "                os.makedirs(directory_path)\n",
    "                print(f\"Directory created: {directory_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffb377-a6b8-47b1-b734-87ece71e26b5",
   "metadata": {},
   "source": [
    "#### Define a filepaths dictionary and save it to config/filepaths.json  to include file paths for each component you will save (review below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92ed297-98fc-4447-8c94-51b29edece2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': {'ml': {'label_encoder': 'Data/label_encoder.joblib',\n",
      "                 'target_lookup': 'Data/target_lookup.joblib',\n",
      "                 'test': 'Data/test_data_ml.joblib',\n",
      "                 'train': 'Data/training_data_ml.joblib'},\n",
      "          'tf': {'test_tf': 'Data/test_ds.joblib',\n",
      "                 'train_tf': 'Data/train_ds.joblib'}},\n",
      " 'Models': {'grid': 'Models/gridsearch_89.joblib',\n",
      "            'ml': 'Models/Gridsearch_full.joblib',\n",
      "            'neural': 'Models/hybrid.joblib'}}\n"
     ]
    }
   ],
   "source": [
    "FPATHS = dict(\n",
    "\n",
    "    Data={\n",
    "        \"ml\":{\n",
    "            \"train\":\"Data/training_data_ml.joblib\",\n",
    "            \"test\":\"Data/test_data_ml.joblib\",\n",
    "            \"target_lookup\":\"Data/target_lookup.joblib\",\n",
    "            \"label_encoder\":\"Data/label_encoder.joblib\",\n",
    "         },\n",
    "        \"tf\":{\n",
    "            \"train_tf\":\"Data/train_ds.joblib\",\n",
    "            \"test_tf\":\"Data/test_ds.joblib\",\n",
    "        },\n",
    "    },\n",
    "\n",
    "    Models={\n",
    "        \"ml\":\"Models/Gridsearch_full.joblib\",\n",
    "        \"grid\":\"Models/gridsearch_89.joblib\",\n",
    "        \"neural\":\"Models/hybrid.joblib\",\n",
    "    }\n",
    ")\n",
    "pprint(FPATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed4377c-de1a-46c9-aa43-4b2c516657c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: Models\n"
     ]
    }
   ],
   "source": [
    "# Use the function on your FPATHS dictionary\n",
    "create_directories_from_paths(FPATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ee032-911f-4fcf-afa2-37a33a52bb51",
   "metadata": {},
   "source": [
    "#### Copy your best models from part 6 into the new notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5afc39b-ee2c-4929-8984-f44ae052a372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df5c3bfb-ba40-4755-b0af-b435b29c90de",
   "metadata": {},
   "source": [
    "#### Update your code to define the final public-facing class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc00c58-2c50-4397-839d-90bd21e40fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "996a4fbb-606f-4e16-9ef2-6878c879abc9",
   "metadata": {},
   "source": [
    "# Part 2: Streamlit App\n",
    "\n",
    "- You will create a Streamlit app to get model predictions for user-entered text.\n",
    "\n",
    "- You may select either your best machine learning model or deep nlp model. ​Note: for portfolio purposes, it would be best to eventually create an app for both.\n",
    "\n",
    "- Create a streamlit app for getting predictions for a user-entered text from your loaded model\n",
    "\n",
    "- (Optional but recommended); Include a Lime Text Explainer explanation for the prediction.\n",
    "\n",
    "- Include the ability to load the training and test data to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17f2ec-e59a-4a1b-9abb-e39f39b9384c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c1505-f212-4bee-9747-147f927b8859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7bb34-7c01-48e9-ac1e-3a151aac133f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
